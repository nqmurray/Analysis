{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PULSE SWITCHING ANALYSIS\n",
    "This notebook will find the critical current for current switching loops and will also perform thermal stability fitting.  Estimations of full switching are done by comparison to the user selected *threshold*.\n",
    "\n",
    "Select file input and threshold below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user inputs\n",
    "dir_path = r'C:\\Users\\Neuromancer\\Desktop\\test' # path to directory\n",
    "file_type = ''\n",
    "normalize_data = True # change to false to see regular y data, default is true\n",
    "\n",
    "# Device characteristics\n",
    "w = 10e-6 # device width (meters)\n",
    "tau = 10 ** -9 # thermal stability factor\n",
    "threshold = 0.3 # resistance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from scipy import optimize\n",
    "from AnalysisFunctions import drop_regions, find_zeros, import_datasets, find_resistance_change\n",
    "\n",
    "all_files = glob.glob(os.path.join(dir_path, '*'+file_type+'*.csv')) # use os.path.join to make os independent\n",
    "[all_files.remove(x) for x in all_files if 'results' in x] # ignore results file\n",
    "\n",
    "if len(all_files) != 0:\n",
    "    full_df = import_datasets(all_files, normalize_data) # if True, data is automatically normalized\n",
    "    display(full_df.head())\n",
    "else:\n",
    "    print(f'No csv files found in {dir_path} with the format: {file_type}!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SELECT DATAFRAME AND GRAPH PARAMETERS:\n",
    "*x_column* is the column used for x values for graphing and data analysis <br>\n",
    "*y_column* is the column used for data analysis <br>\n",
    "*y_normed_column*, if normalize_data is set to true, these values will be the default plot y value <br>\n",
    "*hue_column* is the column used for seperating the data sets into individual line/scatter plots <br>\n",
    "*graph_column* is the column that a set of hue_column values is grouped by <br>\n",
    "\n",
    "The following cell will provide a list of the unique values found in the hue and graph column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_column = 'Current(mA)'\n",
    "y_column = 'Resistance(Ohm)'\n",
    "y_normed_column = 'Normalized Resistance(Ohm)'\n",
    "hue_column = 'Pulse width s' # column to determine how lines should be colored\n",
    "graph_column = 'Applied in-plane field (Oe)' # seperates data by this column to graph plots (multi-hued)\n",
    "\n",
    "full_df[hue_column] = full_df[hue_column].apply(lambda x: round(x, 2)) # round to two decimal places\n",
    "full_df[graph_column] = full_df[graph_column].apply(lambda x: round(x, 2))\n",
    "\n",
    "# sorted lists of unique values\n",
    "hue_column_list = np.sort(full_df[hue_column].unique())\n",
    "graph_column_list = np.sort(full_df[graph_column].unique())\n",
    "\n",
    "print(hue_column, 'list values in the dataframe: ' + np.array2string(hue_column_list, separator=','))\n",
    "print(graph_column, 'list values in the dataframe: ' + np.array2string(graph_column_list, separator=','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('bright', len(hue_column_list))\n",
    "f = sns.FacetGrid(full_df, hue=hue_column, col=graph_column, height=7, despine=False)\n",
    "f.map(plt.plot, x_column, y_normed_column).add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IGNORING DATA\n",
    "\n",
    "Should the user wish to ignore any datasets in the following analysis, including the *graph_column*  value : *hue_column* value in the *ignore_dict* in the following cell will drop the said data from the analysis.  The *graph column* should be the key string and the *hue_column* values should be in a list as ints or floats.  To ignore an *graph_column* value, use *hue_column_list* to ignore all data for said value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in dictionary with values to be ignored in the subsequent data processing\n",
    "ignore_dict = {\n",
    "    # use format of dictionary key == graph_column value with values == list(hue_column values to ignore)\n",
    "    '100.0': [0.3],\n",
    "}\n",
    "cleaned_df = full_df.copy() # make copy so original import does not need to be repeated\n",
    "# drop the areas from the full dataframe specified in the ignore_dict\n",
    "cleaned_df, ig_df, not_found = drop_regions(cleaned_df, ignore_dict, graph_column_list, graph_column, hue_column)\n",
    "# update list unique values   \n",
    "hue_column_list = np.sort(cleaned_df[hue_column].unique())\n",
    "graph_column_list = np.sort(cleaned_df[graph_column].unique())\n",
    "\n",
    "for string in not_found:\n",
    "    print(string)\n",
    "\n",
    "# if there was ignored data, plot said data\n",
    "if type(ig_df) == pd.DataFrame:\n",
    "    f = sns.FacetGrid(ig_df, hue=hue_column, col=graph_column, height=7, despine=False)\n",
    "    f.map(plt.plot, x_column, y_column).add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA ANALYSIS:\n",
    "\n",
    "Pulse Switching Data analysis checks for the critical current values closest to the middle of the loop with the lowest index and will also check the total resistance change and compare it to the *threshold* value determined by the user in the first cell.\n",
    "\n",
    "By changing the value of *check_left_right* the user can change how many points before and after a zero intercept should be of the same sign.  Loops that have more than two zeros will automatically be flagged and the user will be prompted whether or not to ignore those loops.\n",
    "\n",
    "When checking the change in resistance, use the *data_percent* variable to select the percentage (as an int) of the data nearest min/max x values to compare. Note that due to there being two y points for each x value, selecting 15 percent will result in a total of **60** percent of the data being compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_left_right = 1 # number of datapoints to compare\n",
    "data_percent = 15 # percent of data to check near min and max values\n",
    "# building the df to the proper size optimizes speed, will be larger than needed if data is ignored\n",
    "coercivity_df = (pd.DataFrame(index = np.arange(len(graph_column_list) * len(hue_column_list)), \n",
    "                              columns=['Positive Critical Current', \n",
    "                                       'Negative Critical Current', \n",
    "                                       'Average Critical Current',\n",
    "                                       'Y Zeros',\n",
    "                                       'Total Resistance Change',\n",
    "                                       'Resist Change % to Threshold',\n",
    "                                       '3+ Zeros',\n",
    "                                       hue_column, \n",
    "                                       graph_column],\n",
    "                             dtype='float')\n",
    "                )\n",
    "\n",
    "# go through cleaned_df and find coercivity values (x data) and save in coercivity_df\n",
    "len_index = 0\n",
    "multi_zero = {}\n",
    "for g in graph_column_list:\n",
    "    # h_list is the specific hue values for each graph value, i.e. skips all values that are ignored\n",
    "    h_list = np.sort(cleaned_df[(cleaned_df[graph_column] == g)][hue_column].unique())\n",
    "    for h in h_list:\n",
    "        # pass in normalized xy values as array for specific loop (graph and hue)\n",
    "        z, flag = find_zeros(cleaned_df[(cleaned_df[graph_column] == g) & (cleaned_df[hue_column] == h)].\n",
    "                                       loc[:, [x_column, y_normed_column]].to_numpy(), \n",
    "                                       check_left_right\n",
    "                                      )\n",
    "        # z1, z2 correspond to the x values where y = 0\n",
    "        delta_r = find_resistance_change(cleaned_df[(cleaned_df[graph_column] == g) \n",
    "                    & (cleaned_df[hue_column] == h)].loc[:, [x_column, y_column]].to_numpy(), data_percent\n",
    "                                        )\n",
    "        if flag == 'True':\n",
    "            if str(g) in multi_zero:\n",
    "                multi_zero[str(g)].append(h)\n",
    "            else:\n",
    "                multi_zero[str(g)] = [h]\n",
    "        if len(z) != 2:\n",
    "            print(f'Coercivity values not found for dataset {hue_column} {h} with {graph_column} {g}')\n",
    "        else:\n",
    "             coercivity_df.loc[len_index] = z + [(z[0] + z[1])/2, 0.0, delta_r, (delta_r/threshold * 100), flag, h, g]\n",
    "        len_index += 1\n",
    "\n",
    "if len(multi_zero) != 0:\n",
    "    for key, value in multi_zero.items():\n",
    "        print(f'Multiple zeros found for loop: {key} {value}')\n",
    "    q = input('Do you wish to ingore data with multiple zeros? (y/n)')\n",
    "    if q == 'Y' or q == 'y':\n",
    "        cleaned_df, ig, nf = drop_regions(cleaned_df, multi_zero, graph_column_list, graph_column, hue_column)\n",
    "        coercivity_df, ig, nf = drop_regions(coercivity_df, multi_zero, graph_column_list, graph_column, hue_column)\n",
    "        hue_column_list = np.sort(cleaned_df[hue_column].unique())\n",
    "        graph_column_list = np.sort(cleaned_df[graph_column].unique())\n",
    "    else:\n",
    "        pass\n",
    "else:\n",
    "    print('Only two zeros detected per loop')\n",
    "    \n",
    "coercivity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data with found points\n",
    "f = sns.FacetGrid(cleaned_df, hue=hue_column, col=graph_column, height=7)\n",
    "f.map(plt.plot, cleaned_df.columns.values[0], cleaned_df.columns.values[2], zorder=0).add_legend()\n",
    "for index, ax in enumerate(f.axes[0]):\n",
    "    ax.scatter(coercivity_df[(coercivity_df[graph_column] == graph_column_list[index])].iloc[:,0].to_numpy(), \n",
    "                       coercivity_df[(coercivity_df[graph_column] == graph_column_list[index])].iloc[:,3].to_numpy(), \n",
    "                       c='black', marker='D', zorder=1)\n",
    "    ax.scatter(coercivity_df[(coercivity_df[graph_column] == graph_column_list[index])].iloc[:,1].to_numpy(), \n",
    "                       coercivity_df[(coercivity_df[graph_column] == graph_column_list[index])].iloc[:,3].to_numpy(),\n",
    "                      c='black', marker='D', zorder=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAVE CRITICAL CURRENT and THRESHOLD DATA\n",
    "Selecting a filename and any specific datasets to ignore the following cell will save a csv with the change in resistance, hue_column and graph_column values.  Thermal stability data can be saved later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Icritical'\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
    "# fill in dictionary with values to be ignored in the subsequent data processing\n",
    "save_ignore_dict = {\n",
    "    # use format of dictionary key == graph_column value with values == list(hue_column values to ignore)\n",
    "    '250.0': [-0.3],\n",
    "}\n",
    "\n",
    "threshold_save_df = coercivity_df.copy() # make copy so original import does not need to be repeated\n",
    "# drop the areas from the full dataframe specified in the ignore_dict\n",
    "threshold_save_df_df, ig_df, not_found = drop_regions(cleaned_df, save_ignore_dict, graph_column_list, graph_column, hue_column)\n",
    "\n",
    "for string in not_found:\n",
    "    print(string)\n",
    "\n",
    "try:\n",
    "    threshold_save_df.to_csv(os.path.join(dir_path, file_type + filename + timestamp + 'results.csv'), \n",
    "                             encoding='utf-8', index=False)\n",
    "    print(os.path.join(dir_path, file_type + filename + timestamp + \n",
    "                       'results.csv') + ' saved successfully')\n",
    "except:\n",
    "    print('Failed to save results.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### THERMAL STABILITY FITTING\n",
    "Using the critical currents found in the previous cells, linear fitting of the upper and lower critical current values is done and the thermal stability  is calculated and stored in a DataFrame.  These results can be graphed and saved in the following cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe containing data that will be saved to final output\n",
    "results_df = (pd.DataFrame(index = np.arange(len(graph_column_list)), \n",
    "                           columns=['Upper Fitting Slope', \n",
    "                                    'Upper Fitting Intercept',\n",
    "                                    'Lower Fitting Slope',\n",
    "                                    'Lower Fitting Intercept',\n",
    "                                    'Upper Thermal Stability', \n",
    "                                    'Lower Thermal Stability',\n",
    "                                    'Average Thermal Stability',\n",
    "                                    graph_column])\n",
    "             )\n",
    "\n",
    "# use scipy fitting useing non-linear least squares fit\n",
    "def linear_test_function(x, m, b):\n",
    "    return (m * x) + b\n",
    "\n",
    "data_index = 0\n",
    "for g in graph_column_list:\n",
    "    try:\n",
    "        x_vals = np.log(coercivity_df[(coercivity_df[graph_column] == g)][hue_column]/tau)\n",
    "        u_params, u_params_covariance = (optimize.curve_fit(linear_test_function, # function to test\n",
    "                                x_vals.values, # x values\n",
    "                                coercivity_df[(coercivity_df[graph_column] == g)]['Positive Critical Current'].to_numpy()) \n",
    "                                         # y values\n",
    "                                )\n",
    "        l_params, l_params_covariance = (optimize.curve_fit(linear_test_function, # function to test\n",
    "                                x_vals.values, # x values\n",
    "                                coercivity_df[(coercivity_df[graph_column] == g)]['Negative Critical Current'].to_numpy())  \n",
    "                                         # y values\n",
    "                                        )\n",
    "        results_df.loc[data_index] = [u_params[0], u_params[1], l_params[0], l_params[1], \n",
    "                                      -(u_params[1]/u_params[0]), -(l_params[1]/l_params[0]), \n",
    "                                      ((-(u_params[1]/u_params[0]) + -(l_params[1]/l_params[0]))/2), g]                             \n",
    "        data_index += 1\n",
    "    except:\n",
    "        print(f\"An error occured with {g} {graph_column}\")\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data with found coercivities and fitting lines\n",
    "f = sns.FacetGrid(coercivity_df, col=graph_column, height=7)\n",
    "coercivity_df[hue_column] = np.log(coercivity_df[hue_column]/tau)\n",
    "f.map(plt.scatter, hue_column, 'Positive Critical Current')\n",
    "for index, ax in enumerate(f.axes[0]):\n",
    "    x_val = coercivity_df[(coercivity_df[graph_column] == graph_column_list[index])].loc[:, hue_column]\n",
    "    ax.scatter(x_val.values, coercivity_df[(coercivity_df[graph_column] == \n",
    "                    graph_column_list[index])].loc[:,'Negative Critical Current'].values, color='orange')\n",
    "    ax.plot(x_val, linear_test_function(x_val.values, *[\n",
    "                    results_df[(results_df[graph_column] == graph_column_list[index])]['Upper Fitting Slope'][0], \n",
    "                    results_df[(results_df[graph_column] == graph_column_list[index])]['Upper Fitting Intercept'][0]]), \n",
    "                    color='blue')\n",
    "    ax.plot(x_val, linear_test_function(x_val.values, *[\n",
    "                results_df[(results_df[graph_column] == graph_column_list[index])]['Lower Fitting Slope'][0], \n",
    "                results_df[(results_df[graph_column] == graph_column_list[index])]['Lower Fitting Intercept'][0]]),\n",
    "                color='orange')\n",
    "    ax.set_ylabel('Critical Current')\n",
    "    ax.set_xlabel('Natural Log of Pulse Width / Tau')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'ThermalStability'\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
    "save_ignore = [\n",
    "    # list of values to ignore go here\n",
    "    # 100,\n",
    "    # -1000,\n",
    "]\n",
    "\n",
    "for n in save_ignore:\n",
    "    try:\n",
    "        results_df = results_df.drop(results_df[(results_df[graph_column] == n)].index, inplace = True)\n",
    "        print(f'Dropped value {n} from the results dataframe')\n",
    "    except:\n",
    "        print(f'Failed to drop value {n}!')\n",
    "\n",
    "try:\n",
    "    results_df.to_csv(os.path.join(dir_path, file_type + filename + timestamp + 'results.csv'), encoding='utf-8', index=False)\n",
    "    print(os.path.join(dir_path, file_type + filename + timestamp + 'results.csv') + ' saved successfully')\n",
    "except:\n",
    "    print('Failed to save results.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
