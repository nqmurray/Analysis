{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMR and USMR DATA ANALYSIS\n",
    "This notebook finds peaks and difference between left and right sides of the measurement data and will perform linear fitting on the results.\n",
    "\n",
    "Select file input parameters below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user inputs\n",
    "dir_path = r'' # path to directory\n",
    "file_type = ''\n",
    "normalize_data = True # change to false to see regular y data, default is true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from scipy import optimize\n",
    "from AnalysisFunctions import drop_regions, import_datasets, find_peaks, find_resistance_change\n",
    "\n",
    "all_files = glob.glob(os.path.join(dir_path, '*'+file_type+'*.csv')) # use os.path.join to make os independent\n",
    "[all_files.remove(x) for x in all_files if 'results.csv' in x] # ignore results file\n",
    "\n",
    "if len(all_files) != 0:\n",
    "    full_df = import_datasets(all_files, normalize_data, norm_to_zero=True) # if True, data is automatically normalized\n",
    "    display(full_df.head())\n",
    "else:\n",
    "    print(f'No csv files found in {dir_path} with the format: {file_type}!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SELECT DATAFRAME AND GRAPH PARAMETERS:\n",
    "*x_column* is the column used for x values for graphing and data analysis <br>\n",
    "*y_column* is the column used for data analysis, can also be selected for graphing <br>\n",
    "*y_normed_column*, if normalize_data is set to true, these values will be the default plot y value <br>\n",
    "*hue_column* is the column used for seperating the data sets into individual line/scatter plots <br>\n",
    "*graph_column* is the column that a set of hue_column values is grouped by <br>\n",
    "\n",
    "The following cell will provide a list of the unique values found in the hue and graph column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_column = 'Field(Oe)'\n",
    "y_column = 'Resistance(Ohm)'\n",
    "y_normed_column = 'Normalized Resistance(Ohm)'\n",
    "hue_column = 'Applied current (mA)' # column to determine how lines should be colored\n",
    "graph_column = 'Applied in-plane field (Oe)' # seperates data by this column to graph plots (multi-hued)\n",
    "\n",
    "full_df[hue_column] = full_df[hue_column].apply(lambda x: round(x, 2)) # round to two decimal places\n",
    "full_df[graph_column] = full_df[graph_column].apply(lambda x: round(x, 2))\n",
    "\n",
    "# sorted lists of unique values\n",
    "hue_column_list = np.sort(full_df[hue_column].unique())\n",
    "graph_column_list = np.sort(full_df[graph_column].unique())\n",
    "\n",
    "print(hue_column, 'list values in the dataframe: ' + np.array2string(hue_column_list, separator=','))\n",
    "print(graph_column, 'list values in the dataframe: ' + np.array2string(graph_column_list, separator=','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('bright', len(hue_column_list))\n",
    "f = sns.FacetGrid(full_df, hue=hue_column, col=graph_column, height=7, despine=False)\n",
    "f.map(plt.plot, x_column, y_normed_column).add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IGNORING DATA\n",
    "\n",
    "Should the user wish to ignore any datasets in the following analysis, including the *graph_column*  value : *hue_column* value in the *ignore_dict* in the following cell will drop the said data from the analysis.  The *graph column* should be the key string and the *hue_column* values should be in a list as ints or floats.  To ignore an *graph_column* value, use *hue_column_list* to ignore all data for said value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in dictionary with values to be ignored in the subsequent data processing\n",
    "ignore_dict = {\n",
    "    # use format of dictionary key == graph_column value with values == list(hue_column values to ignore)\n",
    "    '250.0': [-0.3],\n",
    "}\n",
    "cleaned_df = full_df.copy() # make copy so original import does not need to be repeated\n",
    "# drop the areas from the full dataframe specified in the ignore_dict\n",
    "cleaned_df, ig_df, not_found = drop_regions(cleaned_df, ignore_dict, graph_column_list, graph_column, hue_column)\n",
    "# update list unique values\n",
    "hue_column_list = np.sort(cleaned_df[hue_column].unique())\n",
    "graph_column_list = np.sort(cleaned_df[graph_column].unique())\n",
    "\n",
    "for string in not_found:\n",
    "    print(string)\n",
    "\n",
    "# if there was ignored data, plot said data\n",
    "if type(ig_df) == pd.DataFrame:\n",
    "    f = sns.FacetGrid(ig_df, hue=hue_column, col=graph_column, height=7, despine=False)\n",
    "    f.map(plt.plot, x_column, y_normed_column).add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA ANALYSIS:\n",
    "\n",
    "AMR data analysis consists of parts, the first being finding the average x value between the two peaks and the second is checking the resistance change between the left and right half of a dataset corresponding to a value in the *hue_column_list*.  For USMR datasets just ignore the peak data results.   \n",
    "\n",
    "When checking the change in resistance, use the *data_percent* variable to select the percentage (as an int) of the data nearest min/max x values to compare. Note that due to there being two y points for each x value, selecting 15 percent will result in a total of **60** percent of the data being compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_percent = 15 # percent of data to check near min and max values\n",
    "# building the df to the proper size optimizes speed, will be larger than needed if data is ignored\n",
    "# peaks aren't always positive and negative,\n",
    "coercivity_df = (pd.DataFrame(index = np.arange(len(graph_column_list) * len(hue_column_list)), \n",
    "                              columns=['Right Peak X', \n",
    "                                       'Left Peak X',\n",
    "                                       'Average X',\n",
    "                                       'Right Peak Y',\n",
    "                                       'Left Peak Y',\n",
    "                                       'Normed Right Peak',\n",
    "                                       'Normed Left Peak',\n",
    "                                       'Left-Right Resistance Change',\n",
    "                                       hue_column, \n",
    "                                       graph_column],\n",
    "                             dtype='float')\n",
    "                )\n",
    "\n",
    "# go through cleaned_df and find coercivity values (x data) and save in coercivity_df\n",
    "len_index = 0\n",
    "for g in graph_column_list:\n",
    "    # h_list is the specific hue values for each graph value, i.e. skips all values that are ignored\n",
    "    h_list = np.sort(cleaned_df[(cleaned_df[graph_column] == g)][hue_column].unique())\n",
    "    for h in h_list:\n",
    "        # pass in x and y and normalized y values as array for specific loop (graph and hue)\n",
    "        vals = find_peaks(cleaned_df[(cleaned_df[graph_column] == g) & \n",
    "                         (cleaned_df[hue_column] == h)].loc[:, [x_column, y_column, y_normed_column]].to_numpy())\n",
    "        \n",
    "        delta_r = find_resistance_change(cleaned_df[(cleaned_df[graph_column] == g) & \n",
    "                                        (cleaned_df[hue_column] == h)].loc[:, [x_column, y_column]].to_numpy(), data_percent)\n",
    "        if len(vals) != 7: # list of 8 items if normal\n",
    "            print(f'Issue with dataset {hue_column} {h} with {graph_column} {g}')\n",
    "        else:\n",
    "            coercivity_df.loc[len_index] = vals + [delta_r, h, g]\n",
    "        len_index += 1\n",
    "        \n",
    "coercivity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data with found points\n",
    "f = sns.FacetGrid(cleaned_df, hue=hue_column, col=graph_column, height=7)\n",
    "f.map(plt.plot, cleaned_df.columns.values[0], cleaned_df.columns.values[2], zorder=0).add_legend()\n",
    "for index, ax in enumerate(f.axes[0]):\n",
    "    ax.scatter(coercivity_df[(coercivity_df[graph_column] == graph_column_list[index])].iloc[:,0].to_numpy(), \n",
    "                       coercivity_df[(coercivity_df[graph_column] == graph_column_list[index])].iloc[:,5].to_numpy(), \n",
    "                       c='black', marker='D', zorder=1)\n",
    "    ax.scatter(coercivity_df[(coercivity_df[graph_column] == graph_column_list[index])].iloc[:,1].to_numpy(), \n",
    "                       coercivity_df[(coercivity_df[graph_column] == graph_column_list[index])].iloc[:,6].to_numpy(),\n",
    "                      c='black', marker='D', zorder=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAVE USMR DATA\n",
    "\n",
    "Selecting a filename and any specific datasets to ignore the following cell will save a csv with the change in resistance, hue_column and graph_column values.  AMR data can be saved later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = ''\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
    "save_ignore = {\n",
    "    #'-1200': [0.3]\n",
    "}\n",
    "\n",
    "\n",
    "coercivity_df, ig_df, not_found = drop_regions(coercivity_df, save_ignore, graph_column_list, graph_column, hue_column\n",
    "\n",
    "for string in not_found:\n",
    "    print(string)\n",
    "\n",
    "try:\n",
    "    coercivity_df.drop(columns=['Right Peak X', 'Left Peak X', 'Average X', 'Right Peak Y', 'Left Peak Y', 'Normed Right Peak',\n",
    "                                'Normed Left Peak']).to_csv(os.path.join(dir_path, file_type + 'USMR-results.csv'), \n",
    "                                                            encoding='utf-8', index=False)\n",
    "    print(os.path.join(dir_path, file_type + filename + timestamp + 'results.csv') + ' saved successfully')\n",
    "except:\n",
    "    print('Failed to save results.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AMR RESULTS\n",
    "\n",
    "Using scipy optimization for a linear fitting, the average x values and the fitting line for average x vs *hue_column* values are plotted.  These parameters are stored in a DataFrame which can be saved in the last cell of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe containing data that will be saved to final output\n",
    "results_df = (pd.DataFrame(index = np.arange(len(graph_column_list)), \n",
    "                           columns=['Fitting Slope', \n",
    "                                    'Fitting Intercept',  \n",
    "                                    graph_column])\n",
    "             )\n",
    "\n",
    "# use scipy fitting useing non-linear least squares fit\n",
    "def linear_test_function(x, m, b):\n",
    "    return (m * x) + b\n",
    "\n",
    "data_index = 0\n",
    "for g in graph_column_list:\n",
    "    try:\n",
    "        params, params_covariance = (optimize.curve_fit(linear_test_function, # function to test\n",
    "                                coercivity_df[(coercivity_df[graph_column] == g)][hue_column].to_numpy(), # x values\n",
    "                                coercivity_df[(coercivity_df[graph_column] == g)]['Average X'].to_numpy()) # y values\n",
    "                                )\n",
    "\n",
    "        results_df.loc[data_index] = [params[0], params[1], g]\n",
    "        data_index += 1\n",
    "    except:\n",
    "        print(f\"An error occured with {g} {graph_column}\")\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data with found coercivities and fitting lines\n",
    "f = sns.FacetGrid(coercivity_df, col=graph_column, height=7)\n",
    "f.map(plt.scatter, hue_column, 'Average X')\n",
    "for index, ax in enumerate(f.axes[0]):\n",
    "    ax.set_ylabel('Field Average (Oe)')\n",
    "    ax.plot(coercivity_df[(coercivity_df[graph_column] == graph_column_list[index])].loc[:, hue_column], \n",
    "              linear_test_function(coercivity_df[(coercivity_df[graph_column] == graph_column_list[index])].loc[:, hue_column].to_numpy(),\n",
    "                *[\n",
    "                    results_df[(results_df[graph_column] == graph_column_list[index])]['Fitting Slope'][0], # slope per graph value\n",
    "                    results_df[(results_df[graph_column] == graph_column_list[index])]['Fitting Intercept'][0] # intercept per graph value\n",
    "                                                        ]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = ''\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
    "save_ignore = [\n",
    "    # list of values to ignore go here\n",
    "    # 100,\n",
    "    # -1000,\n",
    "]\n",
    "\n",
    "for n in save_ignore:\n",
    "    try:\n",
    "        results_df = results_df.drop(results_df[(results_df[graph_column] == n)].index, inplace = True)\n",
    "        print(f'Dropped value {n} from the results dataframe')\n",
    "    except:\n",
    "        print(f'Failed to drop value {n}!')\n",
    "\n",
    "try:\n",
    "    results_df.to_csv(os.path.join(dir_path, file_type + 'AMR-results.csv'), encoding='utf-8', index=False)\n",
    "    print(os.path.join(dir_path, file_type + filename + timestamp + 'results.csv') + ' saved successfully')\n",
    "except:\n",
    "    print('Failed to save results.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
