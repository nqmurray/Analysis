{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AHE DATA ANALYSIS\n",
    "This notebook finds the coercive field values for AHE measurements and will perform loopshift analysis to find the linear fit of average coercivity vs applied current.  Further input of proper device characteristics will provide estimations of effective field per current density and the spin hall angle.\n",
    "\n",
    "Select file input and device parameters below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user inputs\n",
    "dir_path = r'C:\\Users\\Neuromancer\\Desktop\\test' # path to directory\n",
    "file_type = '750'\n",
    "normalize_data = True # change to false to see regular y data, default is true\n",
    "\n",
    "# Device characteristics\n",
    "w = 10e-6 # device width (meters)\n",
    "d = 4e-9 # thickness of spin Hall material (meters) \n",
    "t = 1.4e-9 # thickness of magnetic layer - dead layer (meters)\n",
    "M = 1500 * 1000 # saturization magnetization (A/m)\n",
    "rho_FM = 40 # resistivity of magnetic layer (uOhm-cm)\n",
    "rho_HM = 300 # resistivity of spin Hall material (uOhm-cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from scipy import optimize\n",
    "from AnalysisFunctions import drop_regions, find_zeros, import_datasets\n",
    "\n",
    "all_files = glob.glob(os.path.join(dir_path, '*'+file_type+'*.csv')) # use os.path.join to make os independent\n",
    "[all_files.remove(x) for x in all_files if 'results.csv' in x] # ignore results file\n",
    "\n",
    "if len(all_files) != 0:\n",
    "    full_df = import_datasets(all_files, normalize_data) # if True, data is automatically normalized\n",
    "    display(full_df.head())\n",
    "else:\n",
    "    print(f'No csv files found in {dir_path} with the format: {file_type}!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SELECT DATAFRAME AND GRAPH PARAMETERS:\n",
    "*x_column* is the column used for x values for graphing and data analysis <br>\n",
    "*y_column* is the column used for data analysis and graphing <br>\n",
    "*hue_column* is the column used for seperating the data sets into individual line/scatter plots <br>\n",
    "*graph_column* is the column that a set of hue_column values is grouped by <br>\n",
    "\n",
    "The following cell will provide a list of the unique values found in the hue and graph column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_column = 'Field(Oe)' # plot x data values\n",
    "y_column = 'Normalized Voltage(mV)' # plot y data values\n",
    "hue_column = 'Applied current (mA)' # column to determine how lines should be colored\n",
    "graph_column = 'Applied in-plane field (Oe)' # seperates data by this column to graph plots (multi-hued)\n",
    "\n",
    "full_df[hue_column] = full_df[hue_column].apply(lambda x: round(x, 2)) # round to two decimal places\n",
    "full_df[graph_column] = full_df[graph_column].apply(lambda x: round(x, 2))\n",
    "\n",
    "# sorted lists of unique values\n",
    "hue_column_list = np.sort(full_df[hue_column].unique())\n",
    "graph_column_list = np.sort(full_df[graph_column].unique())\n",
    "# print values so they are easy to paste into the ignore function\n",
    "print(hue_column, 'list values in the dataframe: ' + np.array2string(hue_column_list, separator=','))\n",
    "print(graph_column, 'list values in the dataframe: ' + np.array2string(graph_column_list, separator=','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('bright', len(hue_column_list))\n",
    "f = sns.FacetGrid(full_df, hue=hue_column, col=graph_column, height=7, despine=False)\n",
    "f.map(plt.plot, x_column, y_column).add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IGNORING DATA\n",
    "\n",
    "Should the user wish to ignore any datasets in the following analysis, including the *graph_column*  value : *hue_column* value in the *ignore_dict* in the following cell will drop the said data from the analysis.  The *graph column* should be the key string and the *hue_column* values should be in a list as ints or floats.  To ignore an *graph_column* value, use *hue_column_list* to ignore all data for said value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in dictionary with values to be ignored in the subsequent data processing\n",
    "ignore_dict = {\n",
    "    # use format of dictionary key == graph_column value with values == list(hue_column values to ignore)\n",
    "    '400.0': [-0.7, -0.3, 0.5],\n",
    "}\n",
    "# make copy so original import does not need to be repeated\n",
    "cleaned_df = full_df.copy()\n",
    "# drop the areas from the full dataframe specified in the ignore_dict\n",
    "cleaned_df, ig_df, not_found = drop_regions(\n",
    "    cleaned_df, ignore_dict, graph_column_list, graph_column, hue_column)\n",
    "# update the hue and graph columns\n",
    "hue_column_list = np.sort(cleaned_df[hue_column].unique())\n",
    "graph_column_list = np.sort(cleaned_df[graph_column].unique())\n",
    "\n",
    "for string in not_found:\n",
    "    print(string)\n",
    "\n",
    "# if there was ignored data, plot said data\n",
    "if type(ig_df) == pd.DataFrame:\n",
    "    f = sns.FacetGrid(ig_df, hue=hue_column,\n",
    "                      col=graph_column, height=7, despine=False)\n",
    "    f.map(plt.plot, x_column, y_column).add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA ANALYSIS:\n",
    "\n",
    "AHE Data analysis checks for the coercivity values closest to the middle of the loop with the lowest index.  By changing the value of *check_left_right* the user can change how many points before and after a zero intercept should be of the same sign.  Loops that have more than two zeros will automatically be flagged and the user will be prompted whether or not to ignore those loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of datapoints to compare\n",
    "check_left_right = 1\n",
    "\n",
    "# building the df to the proper size optimizes speed, will be larger than needed if data is ignored\n",
    "coercivity_df = (pd.DataFrame(index=np.arange(len(graph_column_list) * len(hue_column_list)),\n",
    "                              columns=['Positive X Coercivity',\n",
    "                                       'Negative X Coercivity',\n",
    "                                       'Average Coercivity',\n",
    "                                       'Y Zeros',\n",
    "                                       '3+ Zeros',\n",
    "                                       hue_column,\n",
    "                                       graph_column],\n",
    "                              dtype='float')\n",
    "                 )\n",
    "\n",
    "# go through cleaned_df and find coercivity values (x data) and save in coercivity_df\n",
    "len_index = 0\n",
    "multi_zero = {}\n",
    "for g in graph_column_list:\n",
    "    # h_list is the specific hue values for each graph value, i.e. skips all values that are ignored\n",
    "    h_list = np.sort(\n",
    "        cleaned_df[(cleaned_df[graph_column] == g)][hue_column].unique())\n",
    "    for h in h_list:\n",
    "        # from dataframe of of specific graph_column and hue_column values pass xy values as a numpy array\n",
    "        z, flag = find_zeros(cleaned_df[(cleaned_df[graph_column] == g) & (cleaned_df[hue_column] == h)]\n",
    "                             .loc[:, [x_column, y_column]].to_numpy(),\n",
    "                             check_left_right)\n",
    "\n",
    "        if flag == 'True':\n",
    "            if str(g) in multi_zero:\n",
    "                multi_zero[str(g)].append(h)\n",
    "            else:\n",
    "                multi_zero[str(g)] = [h]\n",
    "        if len(z) != 2:\n",
    "            print(\n",
    "                f'Coercivity values not found for dataset {hue_column} {h} with {graph_column} {g}')\n",
    "        else:\n",
    "            coercivity_df.loc[len_index] = z + \\\n",
    "                [(z[0] + z[1]) / 2, 0.0, flag, h, g]\n",
    "        len_index += 1\n",
    "\n",
    "if len(multi_zero) != 0:\n",
    "    for key, value in multi_zero.items():\n",
    "        print(f'Multiple zeros found for loop: {key} {value}')\n",
    "    q = input('Do you wish to ingore data with multiple zeros? (y/n)')\n",
    "    if q == 'Y' or q == 'y':\n",
    "        cleaned_df, ig, nf = drop_regions(\n",
    "            cleaned_df, multi_zero, graph_column_list, graph_column, hue_column)\n",
    "        coercivity_df, ig, nf = drop_regions(\n",
    "            coercivity_df, multi_zero, graph_column_list, graph_column, hue_column)\n",
    "        hue_column_list = np.sort(cleaned_df[hue_column].unique())\n",
    "        graph_column_list = np.sort(cleaned_df[graph_column].unique())\n",
    "    else:\n",
    "        pass\n",
    "else:\n",
    "    print('Only two zeros detected per loop')\n",
    "\n",
    "coercivity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data with found points\n",
    "f = sns.FacetGrid(cleaned_df, hue=hue_column,\n",
    "                  col=graph_column, height=7, despine=False)\n",
    "f.map(plt.plot, x_column, y_column, zorder=0).add_legend()\n",
    "for index, ax in enumerate(f.axes[0]):\n",
    "    ax.scatter(coercivity_df[(coercivity_df[graph_column] == graph_column_list[index])].iloc[:, 0].to_numpy(),\n",
    "               coercivity_df[(coercivity_df[graph_column] ==\n",
    "                              graph_column_list[index])].iloc[:, 3].to_numpy(),\n",
    "               c='black', marker='D', zorder=1)\n",
    "    ax.scatter(coercivity_df[(coercivity_df[graph_column] == graph_column_list[index])].iloc[:, 1].to_numpy(),\n",
    "               coercivity_df[(coercivity_df[graph_column] ==\n",
    "                              graph_column_list[index])].iloc[:, 3].to_numpy(),\n",
    "               c='black', marker='D', zorder=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AHE RESULTS\n",
    "Slope, intercept, Effective Field per Current and Spin Hall Angle are found for each unique value of the *graph_column* and stored in a DataFrame.  Regardless of the device specific parameters determined by the user in the first cell, the fitting slope and intercept for each graph should be accurate to the dataset. The user has the option to ignore any specific data when saving the DataFrame in the last cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe containing data that will be saved to final output\n",
    "results_df = (pd.DataFrame(index=np.arange(len(graph_column_list)),\n",
    "                           columns=['Fitting Slope',\n",
    "                                    'Fitting Intercept',\n",
    "                                    'Effective Field Per Current (Oe/A*m^-2)',\n",
    "                                    'Spin Hall Angle',\n",
    "                                    graph_column])\n",
    "              )\n",
    "\n",
    "# use scipy fitting useing non-linear least squares fit\n",
    "\n",
    "\n",
    "def linear_test_function(x, m, b):\n",
    "    return (m * x) + b\n",
    "\n",
    "\n",
    "data_index = 0\n",
    "for g in graph_column_list:\n",
    "    try:\n",
    "        params, params_covariance = (optimize.curve_fit(linear_test_function,  # function to test\n",
    "                                                        coercivity_df[(\n",
    "                                                            coercivity_df[graph_column] == g)][hue_column].to_numpy(),  # x values\n",
    "                                                        coercivity_df[(coercivity_df[graph_column] == g)]['Average Coercivity'].to_numpy())  # y values\n",
    "                                     )\n",
    "        # Current distribution ratio\n",
    "        ratio = (rho_FM * d) / (rho_FM * d + rho_HM * t)\n",
    "        # Calculations of switching currents/SOT efficiency/etc.\n",
    "        HperJ = (params[0] * 10e11 * (1 / 1000) * (w * d)) / \\\n",
    "            ratio  # H/J in Oe/A*m^-2 * 10e11\n",
    "        she = (2 * M * t * w * d * params[0]) / \\\n",
    "            (10 * 6.6e-16) * (2 / math.pi) / ratio\n",
    "        results_df.loc[data_index] = [params[0], params[1], HperJ, she, g]\n",
    "        data_index += 1\n",
    "    except:\n",
    "        print(f\"An error occured with {g} {graph_column}\")\n",
    "\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data with found coercivities and fitting lines\n",
    "f = sns.FacetGrid(coercivity_df, col=graph_column, height=7, despine=False)\n",
    "f.map(plt.scatter, hue_column, 'Average Coercivity')\n",
    "for index, ax in enumerate(f.axes[0]):\n",
    "    ax.scatter(coercivity_df[(coercivity_df[graph_column] == graph_column_list[index])].loc[:, hue_column].to_numpy(),\n",
    "               coercivity_df[(coercivity_df[graph_column] == graph_column_list[index])\n",
    "                             ].loc[:, 'Positive X Coercivity'].to_numpy(),\n",
    "               color='green')\n",
    "    ax.scatter(coercivity_df[(coercivity_df[graph_column] == graph_column_list[index])].loc[:, hue_column].to_numpy(),\n",
    "               coercivity_df[(coercivity_df[graph_column] == graph_column_list[index])\n",
    "                             ].loc[:, 'Negative X Coercivity'].to_numpy(),\n",
    "               color='orange')\n",
    "    ax.plot(coercivity_df[(coercivity_df[graph_column] == graph_column_list[index])].loc[:, hue_column],\n",
    "            linear_test_function(coercivity_df[(coercivity_df[graph_column] == graph_column_list[index])].loc[:, hue_column].to_numpy(),\n",
    "                                 *[\n",
    "                results_df[(results_df[graph_column] == graph_column_list[index])\n",
    "                           ]['Fitting Slope'].to_numpy()[0],  # slope per graph value\n",
    "                results_df[(results_df[graph_column] == graph_column_list[index])\n",
    "                           ]['Fitting Intercept'].to_numpy()[0]  # intercept per graph value\n",
    "            ]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Loopshift'\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
    "save_ignore = [\n",
    "    # list of values to ignore go here\n",
    "    # 100,\n",
    "    # -1000,\n",
    "]\n",
    "\n",
    "for n in save_ignore:\n",
    "    try:\n",
    "        results_df = results_df.drop(\n",
    "            results_df[(results_df[graph_column] == n)].index, inplace=True)\n",
    "        print(f'Dropped value {n} from the results dataframe')\n",
    "    except:\n",
    "        print(f'Failed to drop value {n}!')\n",
    "\n",
    "try:\n",
    "    results_df.to_csv(os.path.join(dir_path, file_type + filename +\n",
    "                                   timestamp + 'results.csv'), encoding='utf-8', index=False)\n",
    "    print(os.path.join(dir_path, file_type + filename +\n",
    "                       timestamp + 'results.csv') + ' saved successfully')\n",
    "except:\n",
    "    print('Failed to save results.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
